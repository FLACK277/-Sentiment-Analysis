{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91517c0c-f656-4997-8f9d-008aae1fe2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the dataset...\n",
      "\n",
      "Dataset shape: (24113, 7)\n",
      "\n",
      "Column names: ['product_name', 'overall_rating', 'no_ratings', 'no_reviews', 'rating', 'title', 'review']\n",
      "\n",
      "First few rows:\n",
      "                                        product_name  overall_rating  \\\n",
      "0  Apple MacBook AIR Apple M2 - (8 GB/256 GB SSD/...             4.7   \n",
      "1  Apple MacBook AIR Apple M2 - (8 GB/256 GB SSD/...             4.7   \n",
      "2  Apple MacBook AIR Apple M2 - (8 GB/256 GB SSD/...             4.7   \n",
      "3  Apple MacBook AIR Apple M2 - (8 GB/256 GB SSD/...             4.7   \n",
      "4  Apple MacBook AIR Apple M2 - (8 GB/256 GB SSD/...             4.7   \n",
      "\n",
      "  no_ratings no_reviews  rating             title  \\\n",
      "0     15,210        900       5  Perfect product!   \n",
      "1     15,210        900       5         Fabulous!   \n",
      "2     15,210        900       5         Fabulous!   \n",
      "3     15,210        900       4        Delightful   \n",
      "4     15,210        900       5           Awesome   \n",
      "\n",
      "                                              review  \n",
      "0  Loved it, it's my first MacBook that I earned ...  \n",
      "1  Battery lasted longer than my first relationsh...  \n",
      "2  Such a great deal.. very happy with the perfor...  \n",
      "3  Awesome build quality and very good display, b...  \n",
      "4  When i ordered and came to know about seller r...  \n",
      "\n",
      "Missing values per column:\n",
      "product_name      0\n",
      "overall_rating    0\n",
      "no_ratings        0\n",
      "no_reviews        0\n",
      "rating            0\n",
      "title             0\n",
      "review            0\n",
      "dtype: int64\n",
      "\n",
      "Creating sentiment target based on ratings...\n",
      "\n",
      "Sentiment class distribution:\n",
      "sentiment\n",
      "positive    19601\n",
      "negative     4512\n",
      "Name: count, dtype: int64\n",
      "Percentage of positive reviews: 81.29%\n",
      "\n",
      "Preprocessing text data...\n",
      "\n",
      "Example of processed text:\n",
      "perfect product loved first macbook earned hardwork\n",
      "\n",
      "Training set size: 19290\n",
      "Testing set size: 4823\n",
      "\n",
      "Building and training SVM model with hyperparameter tuning...\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "\n",
      "Best SVM parameters:\n",
      "{'classifier__C': 10, 'classifier__gamma': 'scale', 'classifier__kernel': 'rbf', 'tfidf__max_features': 3000, 'tfidf__ngram_range': (1, 2)}\n",
      "\n",
      "SVM Test Accuracy: 0.9840348330914369\n",
      "\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.98      0.93      0.96       902\n",
      "    positive       0.98      1.00      0.99      3921\n",
      "\n",
      "    accuracy                           0.98      4823\n",
      "   macro avg       0.98      0.96      0.97      4823\n",
      "weighted avg       0.98      0.98      0.98      4823\n",
      "\n",
      "\n",
      "Building and training Random Forest model with hyperparameter tuning...\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "\n",
      "Best Random Forest parameters:\n",
      "{'classifier__max_depth': None, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 200, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 2)}\n",
      "\n",
      "Random Forest Test Accuracy: 0.9809247356417168\n",
      "\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.98      0.92      0.95       902\n",
      "    positive       0.98      0.99      0.99      3921\n",
      "\n",
      "    accuracy                           0.98      4823\n",
      "   macro avg       0.98      0.96      0.97      4823\n",
      "weighted avg       0.98      0.98      0.98      4823\n",
      "\n",
      "\n",
      "Examining misclassified examples...\n",
      "\n",
      "Sample of 5 misclassified examples:\n",
      "\n",
      "Product: Infinix X1 Slim Series Intel Core i5 10th Gen 1035G1 - (16 GB/...\n",
      "Original Rating: 4\n",
      "Original Review: Too much noise from the fan. Seems like P3 PC of old era...\n",
      "Actual Sentiment: positive\n",
      "Predicted Sentiment: negative\n",
      "--------------------------------------------------\n",
      "\n",
      "Product: HP 15s Intel Core i5 12th Gen 1235U - (16 GB/512 GB SSD/Window...\n",
      "Original Rating: 3\n",
      "Original Review: Though the laptop is good, you will face issues with MS Office. MS office 2021 not pre installed and...\n",
      "Actual Sentiment: negative\n",
      "Predicted Sentiment: positive\n",
      "--------------------------------------------------\n",
      "\n",
      "Product: Lenovo IdeaPad 3 Intel Core i3 10th Gen 10110U - (8 GB/256 GB ...\n",
      "Original Rating: 3\n",
      "Original Review: It's just nice ðŸ‘\n",
      "Value for money also good\n",
      "and battery ðŸ”‹performance is also very good...\n",
      "Actual Sentiment: negative\n",
      "Predicted Sentiment: positive\n",
      "--------------------------------------------------\n",
      "\n",
      "Product: Acer Aspire 7 Intel Core i5 13th Gen 13420H - (16 GB/512 GB SS...\n",
      "Original Rating: 3\n",
      "Original Review: Battery backup is only for approximately 3-5hrs. If performance applications and games are used then...\n",
      "Actual Sentiment: negative\n",
      "Predicted Sentiment: positive\n",
      "--------------------------------------------------\n",
      "\n",
      "Product: ASUS Vivobook 14 Intel Core i3 13th Gen 1315U - (8 GB/512 GB S...\n",
      "Original Rating: 3\n",
      "Original Review: Mouse pad not working and it was just after 2 week of purchase....\n",
      "Actual Sentiment: negative\n",
      "Predicted Sentiment: positive\n",
      "--------------------------------------------------\n",
      "\n",
      "Top 20 most important words for sentiment prediction:\n",
      "1. fair: 0.0301\n",
      "2. okay: 0.0281\n",
      "3. bad: 0.0271\n",
      "4. job: 0.0250\n",
      "5. worst: 0.0226\n",
      "6. poor: 0.0225\n",
      "7. decent product: 0.0204\n",
      "8. dont: 0.0157\n",
      "9. decent: 0.0154\n",
      "10. waste: 0.0147\n",
      "11. waste money: 0.0146\n",
      "12. good: 0.0121\n",
      "13. worthless: 0.0117\n",
      "14. dont buy: 0.0104\n",
      "15. unsatisfactory: 0.0102\n",
      "16. hated: 0.0097\n",
      "17. battery: 0.0097\n",
      "18. disappointed: 0.0095\n",
      "19. horrible: 0.0088\n",
      "20. best: 0.0087\n",
      "WordCloud package not installed. Skipping word cloud visualization.\n",
      "\n",
      "Analysis complete! Models have been trained and evaluated.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "try:\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    nltk.download('wordnet', quiet=True)\n",
    "    nltk.download('omw-1.4', quiet=True)\n",
    "except:\n",
    "    print(\"NLTK download failed, but continuing...\")\n",
    "\n",
    "# Load the dataset\n",
    "print(\"Loading the dataset...\")\n",
    "df = pd.read_csv('Downloads/laptops_dataset_final_600.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"\\nDataset shape:\", df.shape)\n",
    "print(\"\\nColumn names:\", df.columns.tolist())\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Handle missing values\n",
    "df = df.dropna(subset=['review'])  # Drop rows where review is missing\n",
    "df['title'] = df['title'].fillna('')  # Fill missing titles with empty string\n",
    "\n",
    "# Create a sentiment column based on rating\n",
    "# Ratings > 3 are positive, <= 3 are negative\n",
    "print(\"\\nCreating sentiment target based on ratings...\")\n",
    "df['sentiment'] = df['rating'].apply(lambda x: 'positive' if x > 3 else 'negative')\n",
    "\n",
    "# Check class distribution\n",
    "print(\"\\nSentiment class distribution:\")\n",
    "print(df['sentiment'].value_counts())\n",
    "print(f\"Percentage of positive reviews: {(df['sentiment'] == 'positive').mean() * 100:.2f}%\")\n",
    "\n",
    "# Text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # Remove punctuation and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Remove stopwords and lemmatize\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    words = text.split()\n",
    "    filtered_words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    \n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Apply preprocessing to title and review columns\n",
    "print(\"\\nPreprocessing text data...\")\n",
    "df['processed_review'] = df['review'].apply(preprocess_text)\n",
    "df['processed_title'] = df['title'].apply(preprocess_text)\n",
    "\n",
    "# Combine title and review for better features\n",
    "df['processed_text'] = df['processed_title'] + \" \" + df['processed_review']\n",
    "\n",
    "# Encode target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['sentiment'])\n",
    "\n",
    "# Feature matrix\n",
    "X = df['processed_text']\n",
    "\n",
    "# Print processed examples\n",
    "print(\"\\nExample of processed text:\")\n",
    "print(X.iloc[0])\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"\\nTraining set size: {X_train.shape[0]}\")\n",
    "print(f\"Testing set size: {X_test.shape[0]}\")\n",
    "\n",
    "# Create a pipeline with TF-IDF vectorization and Support Vector Machine classifier\n",
    "print(\"\\nBuilding and training SVM model with hyperparameter tuning...\")\n",
    "svm_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=5000)),\n",
    "    ('classifier', SVC(random_state=42))\n",
    "])\n",
    "\n",
    "# Define hyperparameter grid for SVM\n",
    "svm_param_grid = {\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "    'tfidf__max_features': [3000, 5000],\n",
    "    'classifier__C': [0.1, 1, 10],\n",
    "    'classifier__kernel': ['linear', 'rbf'],\n",
    "    'classifier__gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Perform grid search for SVM\n",
    "svm_grid_search = GridSearchCV(\n",
    "    svm_pipeline,\n",
    "    svm_param_grid,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "svm_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best SVM model\n",
    "svm_best = svm_grid_search.best_estimator_\n",
    "print(\"\\nBest SVM parameters:\")\n",
    "print(svm_grid_search.best_params_)\n",
    "\n",
    "# Evaluate SVM on test set\n",
    "svm_y_pred = svm_best.predict(X_test)\n",
    "print(\"\\nSVM Test Accuracy:\", accuracy_score(y_test, svm_y_pred))\n",
    "print(\"\\nSVM Classification Report:\")\n",
    "print(classification_report(y_test, svm_y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "# Confusion Matrix for SVM\n",
    "svm_cm = confusion_matrix(y_test, svm_y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(svm_cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=label_encoder.classes_,\n",
    "            yticklabels=label_encoder.classes_)\n",
    "plt.title('SVM Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.savefig('svm_confusion_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "# Create a pipeline with TF-IDF vectorization and Random Forest classifier\n",
    "print(\"\\nBuilding and training Random Forest model with hyperparameter tuning...\")\n",
    "rf_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=5000)),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Define hyperparameter grid for Random Forest\n",
    "rf_param_grid = {\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "    'tfidf__max_features': [3000, 5000],\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "# Perform grid search for Random Forest\n",
    "rf_grid_search = GridSearchCV(\n",
    "    rf_pipeline,\n",
    "    rf_param_grid,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best Random Forest model\n",
    "rf_best = rf_grid_search.best_estimator_\n",
    "print(\"\\nBest Random Forest parameters:\")\n",
    "print(rf_grid_search.best_params_)\n",
    "\n",
    "# Evaluate Random Forest on test set\n",
    "rf_y_pred = rf_best.predict(X_test)\n",
    "print(\"\\nRandom Forest Test Accuracy:\", accuracy_score(y_test, rf_y_pred))\n",
    "print(\"\\nRandom Forest Classification Report:\")\n",
    "print(classification_report(y_test, rf_y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "# Confusion Matrix for Random Forest\n",
    "rf_cm = confusion_matrix(y_test, rf_y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(rf_cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=label_encoder.classes_,\n",
    "            yticklabels=label_encoder.classes_)\n",
    "plt.title('Random Forest Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.savefig('rf_confusion_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "# Compare models\n",
    "models = ['SVM', 'Random Forest']\n",
    "accuracies = [accuracy_score(y_test, svm_y_pred), accuracy_score(y_test, rf_y_pred)]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=models, y=accuracies)\n",
    "plt.title('Model Comparison - Test Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.savefig('model_comparison.png')\n",
    "plt.close()\n",
    "\n",
    "# Examine misclassified examples\n",
    "print(\"\\nExamining misclassified examples...\")\n",
    "misclassified_indices = np.where(rf_y_pred != y_test)[0]\n",
    "\n",
    "if len(misclassified_indices) > 0:\n",
    "    # Get original indices in the test set\n",
    "    original_indices = X_test.index[misclassified_indices]\n",
    "    \n",
    "    # Sample up to 5 misclassified examples\n",
    "    sample_size = min(5, len(misclassified_indices))\n",
    "    sample_indices = np.random.choice(original_indices, sample_size, replace=False)\n",
    "    \n",
    "    print(f\"\\nSample of {sample_size} misclassified examples:\")\n",
    "    for idx in sample_indices:\n",
    "        print(f\"\\nProduct: {df.loc[idx, 'product_name']}\")\n",
    "        print(f\"Original Rating: {df.loc[idx, 'rating']}\")\n",
    "        print(f\"Original Review: {df.loc[idx, 'review'][:100]}...\")\n",
    "        print(f\"Actual Sentiment: {df.loc[idx, 'sentiment']}\")\n",
    "        print(f\"Predicted Sentiment: {label_encoder.inverse_transform([rf_y_pred[np.where(X_test.index == idx)[0][0]]])[0]}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Feature importance analysis for Random Forest\n",
    "if hasattr(rf_best['classifier'], 'feature_importances_'):\n",
    "    # Get feature names from the vectorizer\n",
    "    tfidf_vectorizer = rf_best.named_steps['tfidf']\n",
    "    feature_names = np.array(tfidf_vectorizer.get_feature_names_out())\n",
    "    \n",
    "    # Get feature importances\n",
    "    importances = rf_best.named_steps['classifier'].feature_importances_\n",
    "    \n",
    "    # Sort feature importances in descending order\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    # Print and plot the top 20 most important features\n",
    "    top_n = 20\n",
    "    top_features = [(feature_names[i], importances[i]) for i in indices[:top_n]]\n",
    "    \n",
    "    print(\"\\nTop 20 most important words for sentiment prediction:\")\n",
    "    for i, (feature, importance) in enumerate(top_features, 1):\n",
    "        print(f\"{i}. {feature}: {importance:.4f}\")\n",
    "    \n",
    "    # Plot feature importances\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.title(f\"Top {top_n} Feature Importances (Random Forest)\")\n",
    "    plt.bar(range(top_n), [imp for _, imp in top_features], align='center')\n",
    "    plt.xticks(range(top_n), [feat for feat, _ in top_features], rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('feature_importance.png')\n",
    "    plt.close()\n",
    "\n",
    "# Word cloud visualization for positive and negative sentiments\n",
    "try:\n",
    "    from wordcloud import WordCloud\n",
    "    \n",
    "    # Create word clouds for positive and negative reviews\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Positive reviews\n",
    "    positive_text = ' '.join(df[df['sentiment'] == 'positive']['processed_text'])\n",
    "    if positive_text.strip():\n",
    "        wordcloud_positive = WordCloud(width=600, height=300, background_color='white', \n",
    "                                     max_words=100, contour_width=3, contour_color='steelblue')\n",
    "        wordcloud_positive.generate(positive_text)\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(wordcloud_positive, interpolation='bilinear')\n",
    "        plt.title('Positive Reviews')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    # Negative reviews\n",
    "    negative_text = ' '.join(df[df['sentiment'] == 'negative']['processed_text'])\n",
    "    if negative_text.strip():\n",
    "        wordcloud_negative = WordCloud(width=600, height=300, background_color='white',\n",
    "                                     max_words=100, contour_width=3, contour_color='firebrick')\n",
    "        wordcloud_negative.generate(negative_text)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(wordcloud_negative, interpolation='bilinear')\n",
    "        plt.title('Negative Reviews')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('sentiment_wordclouds.png')\n",
    "    plt.close()\n",
    "except ImportError:\n",
    "    print(\"WordCloud package not installed. Skipping word cloud visualization.\")\n",
    "\n",
    "print(\"\\nAnalysis complete! Models have been trained and evaluated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871fc124-134b-4395-89a9-2d5081246857",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
